{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Mm6_HCHFyoz3DvucfAqWhma-qmSCKOZ-","timestamp":1746377676958}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"37puETfgRzzg"},"source":["# Data Preprocessing\n","\n","In this section, we learn how to preprocess the dataset before we we use it for our machine learning model. We will cover importing libraries, reading csv files, how to take of missing data, how to encode categorical data, feature scaling and splitting the dataset into test and training set."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"8KSsQUmaLi0T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746407701289,"user_tz":240,"elapsed":870,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"fd64a52a-26af-46ad-a16a-55432a6d662f"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks/Machine-Learning-A-Z-Codes-Datasets/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/Python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x16AVm2aMWYg","executionInfo":{"status":"ok","timestamp":1746407701318,"user_tz":240,"elapsed":26,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"8d56edf7-7ea6-45d9-b662-7410beb03243"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Machine-Learning-A-Z-Codes-Datasets/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/Python\n"]}]},{"cell_type":"markdown","metadata":{"id":"EoRP98MpR-qj"},"source":["## Importing the libraries"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib as plt\n","import pandas as pd\n"],"metadata":{"id":"vgk7qGOCOhDX","executionInfo":{"status":"ok","timestamp":1746407701326,"user_tz":240,"elapsed":6,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RopL7tUZSQkT"},"source":["## Importing the dataset"]},{"cell_type":"code","source":["dataset =pd.read_csv('Data.csv')\n","X=dataset.iloc[:,:-1].values\n","y=dataset.iloc[:,-1].values"],"metadata":{"id":"43_QDgymP3iy","executionInfo":{"status":"ok","timestamp":1746407701330,"user_tz":240,"elapsed":7,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"cIbl9ZCLokZn","executionInfo":{"status":"ok","timestamp":1746407701562,"user_tz":240,"elapsed":230,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"d238e297-a232-4feb-8819-5a3c9271edae"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Country   Age   Salary Purchased\n","0   France  44.0  72000.0        No\n","1    Spain  27.0  48000.0       Yes\n","2  Germany  30.0  54000.0        No\n","3    Spain  38.0  61000.0        No\n","4  Germany  40.0      NaN       Yes\n","5   France  35.0  58000.0       Yes\n","6    Spain   NaN  52000.0        No\n","7   France  48.0  79000.0       Yes\n","8  Germany  50.0  83000.0        No\n","9   France  37.0  67000.0       Yes"],"text/html":["\n","  <div id=\"df-fc360420-554e-4b1a-8ffd-82046fb6885c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Country</th>\n","      <th>Age</th>\n","      <th>Salary</th>\n","      <th>Purchased</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>France</td>\n","      <td>44.0</td>\n","      <td>72000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Spain</td>\n","      <td>27.0</td>\n","      <td>48000.0</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Germany</td>\n","      <td>30.0</td>\n","      <td>54000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Spain</td>\n","      <td>38.0</td>\n","      <td>61000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Germany</td>\n","      <td>40.0</td>\n","      <td>NaN</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>France</td>\n","      <td>35.0</td>\n","      <td>58000.0</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Spain</td>\n","      <td>NaN</td>\n","      <td>52000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>France</td>\n","      <td>48.0</td>\n","      <td>79000.0</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Germany</td>\n","      <td>50.0</td>\n","      <td>83000.0</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>France</td>\n","      <td>37.0</td>\n","      <td>67000.0</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc360420-554e-4b1a-8ffd-82046fb6885c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fc360420-554e-4b1a-8ffd-82046fb6885c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fc360420-554e-4b1a-8ffd-82046fb6885c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-787f72be-c9e9-47a4-ae0f-be1949575d53\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-787f72be-c9e9-47a4-ae0f-be1949575d53')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-787f72be-c9e9-47a4-ae0f-be1949575d53 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_b17b9d3f-14cd-4b7a-9d28-3409b7c57942\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b17b9d3f-14cd-4b7a-9d28-3409b7c57942 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('dataset');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"dataset","summary":"{\n  \"name\": \"dataset\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"France\",\n          \"Spain\",\n          \"Germany\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.693792591722527,\n        \"min\": 27.0,\n        \"max\": 50.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          50.0,\n          27.0,\n          35.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12265.579661982732,\n        \"min\": 48000.0,\n        \"max\": 83000.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          83000.0,\n          48000.0,\n          52000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Purchased\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["dataset[\"Age\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"Ldk-s6grSkdN","executionInfo":{"status":"ok","timestamp":1746407701571,"user_tz":240,"elapsed":7,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"14d711ee-e9e4-4d8d-e544-a432ee140125"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    44.0\n","1    27.0\n","2    30.0\n","3    38.0\n","4    40.0\n","5    35.0\n","6     NaN\n","7    48.0\n","8    50.0\n","9    37.0\n","Name: Age, dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>44.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>40.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>35.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>48.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>50.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>37.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"nhfKXNxlSabC"},"source":["## Taking care of missing data\n","\n","If there is any missing data in the dataset, we can replace that missing data in a column, with an average/mean/median/frequent data in that column. To do that we can call `SimpleImputer` from `sklearn.impute`.\n","\n","1. First we import this library.\n","2. Then we create an object of the `SimpleImputer` class where we put the parameter `missing_values=np.nan` and we provide the `strategy='mean'`.\n","3. We call the fit method of `SimpleImputer` class to specify the columns we would like to process/fit with this strategy.\n","4. Then we transform our dataset with the strategy by calling the method `transform` of `SimpleImputer` class.\n"]},{"cell_type":"code","source":["from sklearn.impute import SimpleImputer\n","imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n","imputer.fit(X[:,1:3])\n","#imputer.transform(X[:,1:3])\n","X[:,1:3]=imputer.transform(X[:,1:3])#"],"metadata":{"id":"PQQWfzBCja3C","executionInfo":{"status":"ok","timestamp":1746407701581,"user_tz":240,"elapsed":4,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8G9D-PDQmDRp","executionInfo":{"status":"ok","timestamp":1746407701777,"user_tz":240,"elapsed":192,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"e6e03939-8703-4c0d-d576-626af78f0687"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CriG6VzVSjcK"},"source":["## Encoding categorical data\n","\n","The features which has string/name instead of numerical values such as 'Country' needs to be encoded during the data preprocessing phase. Now in this 'Country' feature, we have three countries France, Germany and Spain. If we encode this country with numbers such as 1,2,3. in future, when we train our model, the model may assume that this order matters. But in reality, it does not. We want to avoid any misinterpretation of the model by assuming some correlation between data which may generate wrong outcomes. Hence, we use One hot encoding, which divides each country to a separate column. One hot encoding also creates binary vectors for each country. In this way, we can encode both indepent variable and dependepent variable. Here the independent variable is the `Country` and dependent variable is the `Purchased`. To do this, we need to import two libraries of `sklearn` which is `ColumnTransformer` and `OneHotEncoder`. First we need to create an object for ColumnTransformer which takes an argument of encoding process name or transmformation we would like to make and what to do with the remaining column. If we do not specify, the remainder column then it will totally ignore those columns. Hence, it is very important to specify the `remainder='passthrough'`. Then, we call the `fit_transform` method to encode the categorical feature and fit it it our original dataframe. This fit_transform will require to be transformed to an numpy array in order to train our future model."]},{"cell_type":"markdown","metadata":{"id":"AhSpdQWeSsFh"},"source":["### Encoding the Independent Variable"]},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough')\n","X=np.array(ct.fit_transform(X))"],"metadata":{"id":"yaCgYWI0v9XZ","executionInfo":{"status":"ok","timestamp":1746407701779,"user_tz":240,"elapsed":144,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mEwkIpPY1PZu","executionInfo":{"status":"ok","timestamp":1746407701781,"user_tz":240,"elapsed":143,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"f4c8ed62-7fc5-4532-83a2-ec9ecaebf79c"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"DXh8oVSITIc6"},"source":["### Encoding the Dependent Variable\n","Now we want to encode the dependent variable `Purchased` which is labeled as `y`"]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","le=LabelEncoder()\n","y=le.fit_transform(y)"],"metadata":{"id":"6UTQTySM2QW1","executionInfo":{"status":"ok","timestamp":1746407701783,"user_tz":240,"elapsed":44,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3br3zB92XPF","executionInfo":{"status":"ok","timestamp":1746407701786,"user_tz":240,"elapsed":44,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"86999fb4-c9d3-4fe0-85b6-38c745ff4556"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1 0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"qb_vcgm3qZKW"},"source":["## Splitting the dataset into the Training set and Test set\n","We need to split our dataset (X,y(=) into train and test set. Ideally, it is recommended to split the data set into 80% from training and 20% for test. However, we need for values such as X_train, y_train, X_test, y_test which is requiered as an input for building our machine laerning model. We call train_test_split class from sklearn.model_selection, then specify test_size=0.2 which means 20% of the data will be sued as test, random_state=1 represents the seed value for the reproducible purpose."]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2, random_state=1)"],"metadata":{"id":"mIDM6iN68XXt","executionInfo":{"status":"ok","timestamp":1746407701787,"user_tz":240,"elapsed":13,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["print(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YB-VKeN89XBU","executionInfo":{"status":"ok","timestamp":1746407701912,"user_tz":240,"elapsed":122,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"388a142e-a908-4aca-ae32-aa80aaaaf1f9"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 35.0 58000.0]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vpnzghaE9XF-","executionInfo":{"status":"ok","timestamp":1746407701917,"user_tz":240,"elapsed":21,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"92f1d720-036c-4179-d69a-d13b94047fa0"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"code","source":["print(y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZMIxDps9XKR","executionInfo":{"status":"ok","timestamp":1746407701949,"user_tz":240,"elapsed":35,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"3bfc0090-6632-418e-fce9-348fe42ed410"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1]\n"]}]},{"cell_type":"code","source":["print(y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvrUWopd9XQn","executionInfo":{"status":"ok","timestamp":1746407702020,"user_tz":240,"elapsed":70,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"4a22a769-1655-4cb9-b8ea-9faf6d48faa6"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"TpGqbS4TqkIR"},"source":["## Feature Scaling\n","Feature scaling needs to be done always after splitting the dataset into training and test set. It is because feature scaling performs normalization/standardization of the data. If we apply feature scaling beore scaling the data into train and test then there will be information leakage from test set to training set. Particularly, our aim is to have a totally new test set to evaluate the training set. Hence, we dont want to have any relation leakage from test to train set.\n","\n","x_standardization = x-mean(x)/standard deviation(x)\n","\n","x_norm=(x-x_min)/(x_max-x_min)\n","\n","x_standardaization works in all time. x_norm only works data with normal distribution.\n","\n","\n","feature scaling should be applied in both x_test and x_train\n","\n","Standardization only needs to be applied in features. It does not need to be applied in the dummy variables.\n","\n","dummy variables means the variables we got after encoding (categorical features)\n","\n","We only apply fit-transform on X_train. fit_transform first calculate the standardization for each value of the feature and then transform the dataset.\n","\n","\n","However, we only apply transform tor X_test, because X_test needs to be scaled with the same scaling of X_train. If we use fit_transform to X_test, it will calculate a new scaling for the X_test, which we do not want."]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","sc=StandardScaler()\n","X_train[:,3:]=sc.fit_transform(X_train[:,3:])\n","X_test[:,3:]=sc.transform(X_test[:,3:])"],"metadata":{"id":"cLQEDas15vKE","executionInfo":{"status":"ok","timestamp":1746407702066,"user_tz":240,"elapsed":44,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["print(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXy4RlRwAR6A","executionInfo":{"status":"ok","timestamp":1746407702124,"user_tz":240,"elapsed":54,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"cdcee379-d7ed-4c4f-8a31-dfd9f647136e"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n"," [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n"," [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n"," [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n"," [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n"," [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n"," [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n"," [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b1Khh_tDAR_N","executionInfo":{"status":"ok","timestamp":1746407702208,"user_tz":240,"elapsed":82,"user":{"displayName":"Shreya Khisa","userId":"05193938709774367390"}},"outputId":"823d39bc-158d-4ce9-ae48-ebd858e40cd7"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n"," [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"]}]}]}